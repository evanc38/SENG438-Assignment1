>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: Group Number   15|
|-----------------|
| Student 1 name:    Evan Cherewko|   
| Student 2 name:    Alex On|   
| Student 3 name:    Ryan Lau|   
| Student 4 name:                |   


**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction](#introduction)

[2 High-level description of the exploratory testing plan](#high-level-description-of-the-exploratory-testing-plan)

[3 Comparison of exploratory and manual functional testing](#comparison-of-exploratory-and-manual-functional-testing)

[4 Notes and discussion of the peer reviews of defect reports](#notes-and-discussion-of-the-peer-reviews-of-defect-reports)

[5 How the pair testing was managed and team work/effort was divided](#how-the-pair-testing-was-managed-and-teamwork-effort-was-divided)

[6 Difficulties encountered, challenges overcome, and lessons learned](#difficulties-encountered-challenges-overcome-and-lessons-learned)

[7 Comments/feedback on the lab and lab document itself](#commentsfeedback-on-the-lab-and-lab-document-itself)


# Introduction

An introduction of your lab work, and what you knew about exploratory and manual
functional testing before this lab

# High-level description of the exploratory testing plan

Our exploratory testing plan is based on the processes and actions that a user will take, ensuring we cover as many issues as the end user could encounter. We will run a couple of instances of what a user will be expected to do, including but not limited to inserting the card, entering a PIN, making different types of transactions, checking the integrity of the transactions, receiving receipts, and successfully logging out. We are going to use this most common path to create a series of test cases to test the average user experience. 

# Comparison of exploratory and manual functional testing

During exploratory testing, we found some bugs quickly and found some bugs that were so unexpected that they may not have been caught during manual functional testing. The issue with exploratory testing is that bugs are much harder to reproduce because there is no precise method to follow while doing the testing, and exploratory testing is not extensive as it is easy to miss something.

Manual functional testing is much more methodical so it is very hard to miss any bugs in areas with detailed manual functional tests. It was slower than exploratory testing but much easier to reproduce found bugs as the tester is following a detailed plan and can reproduce the steps taken by re-doing the same test again. 

Both methods of testing have their own pros and cons, but we think that the best results can be achieved by combining both methods of testing on a SUT.

-   Note that you need to submit a report generated by your defect tracking
    system, containing all defects recorded in the system.

# Notes and discussion of the peer reviews of defect reports

Using a peer review system helped us ensure we did not miss any bugs as the other peers could find the bug as well. Once we
found bugs, we used a peer review system where we reproduced the bug for our peer and they confirmed that behaviour was not as expected. This helped us be sure that bugs were bugs and that we did not make any mistakes while reproducing the bugs. We believe peer reviews of defect reports are important to ensure the accuracy and integrity of the reports.

# How the pair testing was managed and teamwork/effort was divided 

As there were only three members in our group, we invented our own peer method where we rotated who was testing with whom circularly. First peer A tested with peer B, then peer B tested with peer C, then peer C tested with peer A, all taking turns who was reviewing and who was testing for and producing bugs. We used this method through all the manual scripted testing and the exploratory testing. Using this method we think we managed to catch most if not all of the bugs in this SUT.

# Difficulties encountered, challenges overcome, and lessons learned

Initially, some of our team members had issues running the .jar files, and we determined the issue was with our JDK installation, so after reinstalling and repairing our installation, we were able to launch the SUT. Our team then had to overcome the challenge of only having three members in our group. As discussed above we invented methods to still use peer testing. We learned that communication is key when working in peer pairs, and that without proper communication there is no difference from just working alone. 

# Comments/feedback on the lab and lab document itself

We liked the clear and organized presentation of instructions to us for the testing phase of the lab. One area we were confused about was how to export and present our bug reports from our chosen software (azure). This was a fun and engaging way to learn about bug reports and different testing methods.
